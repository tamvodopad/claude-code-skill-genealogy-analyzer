#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–π –º–∏–≥—Ä–∞—Ü–∏–∏ –≤ –≥–µ–Ω–µ–∞–ª–æ–≥–∏—á–µ—Å–∫–æ–º –¥—Ä–µ–≤–µ.
–û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è —Å–µ–º–µ–π –º–µ–∂–¥—É –Ω–∞—Å–µ–ª—ë–Ω–Ω—ã–º–∏ –ø—É–Ω–∫—Ç–∞–º–∏ –ø–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è–º.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python3 migration_analysis.py tree.ged
    python3 migration_analysis.py tree.ged --person @I1@
    python3 migration_analysis.py tree.ged --show-map
"""

import sys
import argparse
import re
from dataclasses import dataclass, field
from typing import Optional, List, Dict, Set, Tuple
from collections import defaultdict

sys.path.insert(0, '.')
from lib import parse_gedcom, Person, Family, GedcomData


@dataclass
class LocationEvent:
    """–°–æ–±—ã—Ç–∏–µ —Å –ª–æ–∫–∞—Ü–∏–µ–π."""
    person: Person
    event_type: str  # birth, death, residence, marriage
    place: str
    year: Optional[int]
    normalized_place: str


@dataclass
class MigrationEvent:
    """–°–æ–±—ã—Ç–∏–µ –º–∏–≥—Ä–∞—Ü–∏–∏."""
    person: Person
    from_place: str
    to_place: str
    year_from: Optional[int]
    year_to: Optional[int]
    event_type: str  # birth_to_death, birth_to_marriage, residence_change


@dataclass
class FamilyMigrationPattern:
    """–ü–∞—Ç—Ç–µ—Ä–Ω –º–∏–≥—Ä–∞—Ü–∏–∏ —Å–µ–º—å–∏."""
    family: Family
    origin_places: List[str]  # –º–µ—Å—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è –ø—Ä–µ–¥–∫–æ–≤
    destination_place: str     # –º–µ—Å—Ç–æ –∂–∏—Ç–µ–ª—å—Å—Ç–≤–∞ —Å–µ–º—å–∏
    distance_generations: int  # —á–µ—Ä–µ–∑ —Å–∫–æ–ª—å–∫–æ –ø–æ–∫–æ–ª–µ–Ω–∏–π


def normalize_place(place: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏—è –º–µ—Å—Ç–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è."""
    if not place:
        return ""

    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    p = place.lower().strip()

    # –£–±–∏—Ä–∞–µ–º —Ç–∏–ø–∏—á–Ω—ã–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è –∏ —É—Ç–æ—á–Ω–µ–Ω–∏—è
    remove_patterns = [
        r'\s*–≥—É–±\.?\s*',
        r'\s*—É–µ–∑–¥\.?\s*',
        r'\s*–≤–æ–ª–æ—Å—Ç—å\.?\s*',
        r'\s*–æ–±–ª\.?\s*',
        r'\s*–æ–±–ª–∞—Å—Ç—å\s*',
        r'\s*—Ä–∞–π–æ–Ω\s*',
        r'\s*—Ä-–Ω\.?\s*',
        r'\s*—Å–µ–ª–æ\s*',
        r'\s*—Å\.\s*',
        r'\s*–¥–µ—Ä–µ–≤–Ω—è\s*',
        r'\s*–¥\.\s*',
        r'\s*–≥–æ—Ä–æ–¥\s*',
        r'\s*–≥\.\s*',
        r'\s*–ø–æ—Å—ë–ª–æ–∫\s*',
        r'\s*–ø\.\s*',
        r'\s*—Å—Ç\.\s*',
        r'\s*—Å—Ç–∞–Ω–∏—Ü–∞\s*',
    ]

    for pattern in remove_patterns:
        p = re.sub(pattern, ' ', p, flags=re.IGNORECASE)

    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    p = ' '.join(p.split())

    return p


def extract_main_place(place: str) -> str:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –Ω–∞—Å–µ–ª—ë–Ω–Ω–æ–≥–æ –ø—É–Ω–∫—Ç–∞ (–ø–µ—Ä–≤–∞—è —á–∞—Å—Ç—å)."""
    if not place:
        return ""

    # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å –¥–æ –∑–∞–ø—è—Ç–æ–π
    parts = place.split(',')
    if parts:
        return parts[0].strip()
    return place.strip()


def extract_region(place: str) -> str:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞ (–≥—É–±–µ—Ä–Ω–∏–∏, –æ–±–ª–∞—Å—Ç–∏)."""
    if not place:
        return ""

    # –ò—â–µ–º –≥—É–±–µ—Ä–Ω–∏—é –∏–ª–∏ –æ–±–ª–∞—Å—Ç—å
    patterns = [
        r'(\w+)\s+–≥—É–±\.?',
        r'(\w+)\s+–≥—É–±–µ—Ä–Ω–∏—è',
        r'(\w+)\s+–æ–±–ª\.?',
        r'(\w+)\s+–æ–±–ª–∞—Å—Ç—å',
    ]

    for pattern in patterns:
        match = re.search(pattern, place, re.IGNORECASE)
        if match:
            return match.group(1).strip()

    # –ü–æ—Å–ª–µ–¥–Ω—è—è —á–∞—Å—Ç—å –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π
    parts = place.split(',')
    if len(parts) > 1:
        return parts[-1].strip()

    return ""


def get_person_locations(person: Person, data: GedcomData) -> List[LocationEvent]:
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –ª–æ–∫–∞—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω—ã."""
    locations = []

    # –†–æ–∂–¥–µ–Ω–∏–µ
    if person.birth_place:
        year = person.birth_date.year if person.birth_date else person.birth_year
        locations.append(LocationEvent(
            person=person,
            event_type='birth',
            place=person.birth_place,
            year=year,
            normalized_place=normalize_place(person.birth_place)
        ))

    # –°–º–µ—Ä—Ç—å
    if person.death_place:
        year = person.death_date.year if person.death_date else person.death_year
        locations.append(LocationEvent(
            person=person,
            event_type='death',
            place=person.death_place,
            year=year,
            normalized_place=normalize_place(person.death_place)
        ))

    # –†–µ–∑–∏–¥–µ–Ω—Ü–∏–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    for residence in getattr(person, 'residences', []):
        if residence.get('place'):
            locations.append(LocationEvent(
                person=person,
                event_type='residence',
                place=residence['place'],
                year=residence.get('year'),
                normalized_place=normalize_place(residence['place'])
            ))

    # –ë—Ä–∞–∫–∏
    for spouse in data.get_spouses(person):
        # –ù–∞—Ö–æ–¥–∏–º —Å–µ–º—å—é
        for fam_id in person.spouse_family_ids:
            family = data.families.get(fam_id)
            if family and family.marriage_place:
                year = family.marriage_date.year if family.marriage_date else family.marriage_year
                locations.append(LocationEvent(
                    person=person,
                    event_type='marriage',
                    place=family.marriage_place,
                    year=year,
                    normalized_place=normalize_place(family.marriage_place)
                ))

    return sorted(locations, key=lambda x: x.year or 9999)


def find_person_migrations(person: Person, data: GedcomData) -> List[MigrationEvent]:
    """–ù–∞–π—Ç–∏ –º–∏–≥—Ä–∞—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω—ã."""
    migrations = []
    locations = get_person_locations(person, data)

    if len(locations) < 2:
        return migrations

    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –ª–æ–∫–∞—Ü–∏–∏
    for i in range(len(locations) - 1):
        loc1 = locations[i]
        loc2 = locations[i + 1]

        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Å—Ç–∞
        place1 = extract_main_place(loc1.place)
        place2 = extract_main_place(loc2.place)

        if place1.lower() != place2.lower() and place1 and place2:
            migrations.append(MigrationEvent(
                person=person,
                from_place=loc1.place,
                to_place=loc2.place,
                year_from=loc1.year,
                year_to=loc2.year,
                event_type=f"{loc1.event_type}_to_{loc2.event_type}"
            ))

    return migrations


def analyze_all_migrations(data: GedcomData) -> Dict:
    """–ê–Ω–∞–ª–∏–∑ –º–∏–≥—Ä–∞—Ü–∏–π –≤—Å–µ–≥–æ –¥—Ä–µ–≤–∞."""
    stats = {
        'total_persons': len(data.persons),
        'persons_with_places': 0,
        'persons_with_migrations': 0,
        'total_migrations': 0,
        'migrations': [],
        'by_place': defaultdict(lambda: {'births': 0, 'deaths': 0, 'arrivals': 0, 'departures': 0}),
        'by_region': defaultdict(lambda: {'births': 0, 'deaths': 0}),
        'migration_routes': defaultdict(int),  # (from, to) -> count
        'by_decade': defaultdict(int),
    }

    for person_id, person in data.persons.items():
        has_place = False

        # –ú–µ—Å—Ç–æ —Ä–æ–∂–¥–µ–Ω–∏—è
        if person.birth_place:
            has_place = True
            main_place = extract_main_place(person.birth_place)
            region = extract_region(person.birth_place)
            stats['by_place'][main_place]['births'] += 1
            if region:
                stats['by_region'][region]['births'] += 1

        # –ú–µ—Å—Ç–æ —Å–º–µ—Ä—Ç–∏
        if person.death_place:
            has_place = True
            main_place = extract_main_place(person.death_place)
            region = extract_region(person.death_place)
            stats['by_place'][main_place]['deaths'] += 1
            if region:
                stats['by_region'][region]['deaths'] += 1

        if has_place:
            stats['persons_with_places'] += 1

        # –ú–∏–≥—Ä–∞—Ü–∏–∏
        migrations = find_person_migrations(person, data)
        if migrations:
            stats['persons_with_migrations'] += 1
            stats['total_migrations'] += len(migrations)
            stats['migrations'].extend(migrations)

            for mig in migrations:
                from_main = extract_main_place(mig.from_place)
                to_main = extract_main_place(mig.to_place)

                stats['by_place'][from_main]['departures'] += 1
                stats['by_place'][to_main]['arrivals'] += 1

                route = (from_main, to_main)
                stats['migration_routes'][route] += 1

                if mig.year_to:
                    decade = (mig.year_to // 10) * 10
                    stats['by_decade'][decade] += 1

    return stats


def analyze_family_origins(data: GedcomData, person: Person, max_gen: int = 5) -> Dict:
    """–ê–Ω–∞–ª–∏–∑ –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏—è —Å–µ–º—å–∏."""
    origins = {
        'person': person,
        'ancestors_by_place': defaultdict(list),
        'generations': {},
    }

    def traverse(p: Person, gen: int, line: str):
        if gen > max_gen:
            return

        if p.birth_place:
            main_place = extract_main_place(p.birth_place)
            origins['ancestors_by_place'][main_place].append({
                'person': p,
                'generation': gen,
                'line': line
            })

            if gen not in origins['generations']:
                origins['generations'][gen] = []
            origins['generations'][gen].append({
                'person': p,
                'place': main_place,
                'line': line
            })

        father, mother = data.get_parents(p)
        if father:
            traverse(father, gen + 1, line + 'F')
        if mother:
            traverse(mother, gen + 1, line + 'M')

    traverse(person, 0, '')
    return origins


def main():
    parser = argparse.ArgumentParser(
        description='–ê–Ω–∞–ª–∏–∑ –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–π –º–∏–≥—Ä–∞—Ü–∏–∏ –≤ –≥–µ–Ω–µ–∞–ª–æ–≥–∏—á–µ—Å–∫–æ–º –¥—Ä–µ–≤–µ'
    )
    parser.add_argument('gedcom_file', help='–ü—É—Ç—å –∫ GEDCOM —Ñ–∞–π–ª—É')
    parser.add_argument('--person', metavar='ID',
                        help='ID –ø–µ—Ä—Å–æ–Ω—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏—è')
    parser.add_argument('--max-gen', type=int, default=5, metavar='N',
                        help='–ì–ª—É–±–∏–Ω–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–µ–¥–∫–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5)')
    parser.add_argument('--top', type=int, default=20, metavar='N',
                        help='–¢–æ–ø N –º–µ—Å—Ç –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è')
    parser.add_argument('--output', '-o', metavar='FILE',
                        help='–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á—ë—Ç –≤ —Ñ–∞–π–ª')

    args = parser.parse_args()

    print(f"–ü–∞—Ä—Å–∏–Ω–≥ GEDCOM —Ñ–∞–π–ª–∞: {args.gedcom_file}")
    data = parse_gedcom(args.gedcom_file)
    print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(data.persons)} –ø–µ—Ä—Å–æ–Ω, {len(data.families)} —Å–µ–º–µ–π\n")

    output_lines = []

    output_lines.append("=" * 100)
    output_lines.append("–ê–ù–ê–õ–ò–ó –ì–ï–û–ì–†–ê–§–ò–ß–ï–°–ö–û–ô –ú–ò–ì–†–ê–¶–ò–ò")
    output_lines.append("=" * 100)

    if args.person:
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø–µ—Ä—Å–æ–Ω—ã
        person = data.get_person(args.person)
        if not person:
            print(f"–û—à–∏–±–∫–∞: –ø–µ—Ä—Å–æ–Ω–∞ {args.person} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            sys.exit(1)

        output_lines.append(f"\nüåç –ì–ï–û–ì–†–ê–§–ò–ß–ï–°–ö–û–ï –ü–†–û–ò–°–•–û–ñ–î–ï–ù–ò–ï: {person.name}")

        origins = analyze_family_origins(data, person, args.max_gen)

        # –ü–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è–º
        output_lines.append("\nüìä –ú–ï–°–¢–ê –†–û–ñ–î–ï–ù–ò–Ø –ü–û –ü–û–ö–û–õ–ï–ù–ò–Ø–ú:")
        gen_names = {0: '–°–∞–º', 1: '–†–æ–¥–∏—Ç–µ–ª–∏', 2: '–ë–∞–±—É—à–∫–∏/–¥–µ–¥—É—à–∫–∏',
                     3: '–ü—Ä–∞–±–∞–±—É—à–∫–∏/–ø—Ä–∞–¥–µ–¥—É—à–∫–∏', 4: '4-–µ –ø–æ–∫–æ–ª–µ–Ω–∏–µ', 5: '5-–µ –ø–æ–∫–æ–ª–µ–Ω–∏–µ'}

        for gen in sorted(origins['generations'].keys()):
            gen_data = origins['generations'][gen]
            places = defaultdict(list)
            for item in gen_data:
                places[item['place']].append(item['person'].name)

            output_lines.append(f"\n   {gen_names.get(gen, f'{gen}-–µ –ø–æ–∫–æ–ª–µ–Ω–∏–µ')}:")
            for place, persons in places.items():
                output_lines.append(f"      üìç {place}: {', '.join(persons)}")

        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Å—Ç–∞
        output_lines.append("\nüè† –û–°–ù–û–í–ù–´–ï –ú–ï–°–¢–ê –ü–†–û–ò–°–•–û–ñ–î–ï–ù–ò–Ø:")
        sorted_places = sorted(origins['ancestors_by_place'].items(),
                               key=lambda x: -len(x[1]))
        for place, ancestors in sorted_places[:10]:
            output_lines.append(f"   {place}: {len(ancestors)} –ø—Ä–µ–¥–∫–æ–≤")
            for anc in ancestors[:3]:
                gen_str = gen_names.get(anc['generation'], f"{anc['generation']}-–µ –ø–æ–∫.")
                output_lines.append(f"      ‚Ä¢ {anc['person'].name} ({gen_str})")

        # –ú–∏–≥—Ä–∞—Ü–∏–∏ —ç—Ç–æ–π –ø–µ—Ä—Å–æ–Ω—ã
        migrations = find_person_migrations(person, data)
        if migrations:
            output_lines.append(f"\nüö∂ –ü–ï–†–ï–ú–ï–©–ï–ù–ò–Ø {person.given_name or person.name}:")
            for mig in migrations:
                year_str = ""
                if mig.year_from and mig.year_to:
                    year_str = f" ({mig.year_from} ‚Üí {mig.year_to})"
                elif mig.year_to:
                    year_str = f" (–¥–æ {mig.year_to})"
                output_lines.append(f"   {mig.from_place} ‚Üí {mig.to_place}{year_str}")

    else:
        # –û–±—â–∏–π –∞–Ω–∞–ª–∏–∑
        stats = analyze_all_migrations(data)

        output_lines.append(f"\nüìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        output_lines.append(f"   –ü–µ—Ä—Å–æ–Ω —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –º–µ—Å—Ç: {stats['persons_with_places']} –∏–∑ {stats['total_persons']}")
        output_lines.append(f"   –ü–µ—Ä—Å–æ–Ω —Å –º–∏–≥—Ä–∞—Ü–∏—è–º–∏: {stats['persons_with_migrations']}")
        output_lines.append(f"   –í—Å–µ–≥–æ –º–∏–≥—Ä–∞—Ü–∏–π: {stats['total_migrations']}")

        # –¢–æ–ø –º–µ—Å—Ç
        if stats['by_place']:
            output_lines.append("\n" + "=" * 100)
            output_lines.append("üèòÔ∏è –¢–û–ü –ù–ê–°–ï–õ–Å–ù–ù–´–• –ü–£–ù–ö–¢–û–í")
            output_lines.append("=" * 100)

            sorted_places = sorted(stats['by_place'].items(),
                                   key=lambda x: -(x[1]['births'] + x[1]['deaths']))

            output_lines.append(f"\n{'–ú–µ—Å—Ç–æ':<40} {'–†–æ–∂–¥.':<8} {'–°–º–µ—Ä—Ç.':<8} {'–ü—Ä–∏–±—ã–ª':<8} {'–£–±—ã–ª':<8}")
            output_lines.append("-" * 80)

            for place, counts in sorted_places[:args.top]:
                if not place:
                    continue
                place_short = place[:38] + '..' if len(place) > 40 else place
                output_lines.append(f"{place_short:<40} {counts['births']:<8} {counts['deaths']:<8} "
                                   f"{counts['arrivals']:<8} {counts['departures']:<8}")

        # –†–µ–≥–∏–æ–Ω—ã
        if stats['by_region']:
            output_lines.append("\n" + "=" * 100)
            output_lines.append("üó∫Ô∏è –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –†–ï–ì–ò–û–ù–ê–ú (–ì–£–ë–ï–†–ù–ò–Ø–ú)")
            output_lines.append("=" * 100)

            sorted_regions = sorted(stats['by_region'].items(),
                                    key=lambda x: -(x[1]['births'] + x[1]['deaths']))

            for region, counts in sorted_regions[:15]:
                if not region:
                    continue
                output_lines.append(f"   {region}: {counts['births']} —Ä–æ–∂–¥–µ–Ω–∏–π, {counts['deaths']} —Å–º–µ—Ä—Ç–µ–π")

        # –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –º–∞—Ä—à—Ä—É—Ç—ã –º–∏–≥—Ä–∞—Ü–∏–∏
        if stats['migration_routes']:
            output_lines.append("\n" + "=" * 100)
            output_lines.append("üö∂ –ü–û–ü–£–õ–Ø–†–ù–´–ï –ú–ê–†–®–†–£–¢–´ –ú–ò–ì–†–ê–¶–ò–ò")
            output_lines.append("=" * 100)

            sorted_routes = sorted(stats['migration_routes'].items(), key=lambda x: -x[1])

            for (from_place, to_place), count in sorted_routes[:15]:
                if count > 1:
                    output_lines.append(f"   {from_place} ‚Üí {to_place}: {count} —á–µ–ª–æ–≤–µ–∫")

        # –ú–∏–≥—Ä–∞—Ü–∏–∏ –ø–æ –¥–µ—Å—è—Ç–∏–ª–µ—Ç–∏—è–º
        if stats['by_decade']:
            output_lines.append("\n" + "=" * 100)
            output_lines.append("üìÖ –ú–ò–ì–†–ê–¶–ò–ò –ü–û –î–ï–°–Ø–¢–ò–õ–ï–¢–ò–Ø–ú")
            output_lines.append("=" * 100)

            max_count = max(stats['by_decade'].values()) if stats['by_decade'] else 1
            for decade in sorted(stats['by_decade'].keys()):
                count = stats['by_decade'][decade]
                bar_len = int(40 * count / max_count)
                bar = "‚ñà" * bar_len
                output_lines.append(f"   {decade}s: {bar} {count}")

    # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
    output_lines.append("\n" + "=" * 100)
    output_lines.append("üìñ –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø")
    output_lines.append("=" * 100)
    output_lines.append("""
   –ê–Ω–∞–ª–∏–∑ –º–∏–≥—Ä–∞—Ü–∏–∏ –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–Ω—è—Ç—å:

   ‚Ä¢ –ì–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏–µ —Å–µ–º—å–∏
   ‚Ä¢ –ü–∞—Ç—Ç–µ—Ä–Ω—ã –ø–µ—Ä–µ—Å–µ–ª–µ–Ω–∏—è (–≥–æ—Ä–æ–¥ ‚Üî –¥–µ—Ä–µ–≤–Ω—è, –º–µ–∂–¥—É –≥—É–±–µ—Ä–Ω–∏—è–º–∏)
   ‚Ä¢ –í–ª–∏—è–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π (–≤–æ–π–Ω—ã, –≥–æ–ª–æ–¥, –∏–Ω–¥—É—Å—Ç—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è)
   ‚Ä¢ –°–≤—è–∑—å —Å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é (—Ä–µ–º–µ—Å–ª–µ–Ω–Ω–∏–∫–∏, —Ç–æ—Ä–≥–æ–≤—Ü—ã)

   –¢–∏–ø–∏—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –†–æ—Å—Å–∏–∏:
   ‚Ä¢ –î–æ 1861 ‚Äî –∫—Ä–µ–ø–æ—Å—Ç–Ω—ã–µ –∫—Ä–µ—Å—Ç—å—è–Ω–µ –ø—Ä–∏–≤—è–∑–∞–Ω—ã –∫ –º–µ—Å—Ç—É
   ‚Ä¢ 1861-1917 ‚Äî —Ä–æ—Å—Ç –º–∏–≥—Ä–∞—Ü–∏–∏ –≤ –≥–æ—Ä–æ–¥–∞
   ‚Ä¢ 1917-1930 ‚Äî —É—Ä–±–∞–Ω–∏–∑–∞—Ü–∏—è –∏ –∫–æ–ª–ª–µ–∫—Ç–∏–≤–∏–∑–∞—Ü–∏—è
   ‚Ä¢ –ü–æ—Å–ª–µ 1930 ‚Äî –∏–Ω–¥—É—Å—Ç—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è, –º–∞—Å—Å–æ–≤—ã–π –ø–µ—Ä–µ–µ–∑–¥ –≤ –≥–æ—Ä–æ–¥–∞
""")

    # –í—ã–≤–æ–¥
    report = "\n".join(output_lines)
    print(report)

    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"\nüíæ –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {args.output}")


if __name__ == '__main__':
    main()
